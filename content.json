{"pages":[],"posts":[{"title":"2020年阅读总结","text":"多灾多难的2020年已经没有几天了，整个2020年要说还真是像一记刹车，去年很多想法，计划都有因为疫情原因搁置了。平时的生活更是从宅家变成了重度宅家的状态，自然就多出了许多大段大段的连续时间，可以用来好好玩玩大作，看看小说。仔细盘点一下今年总共看了10本小说外加2本科普书籍( 2020年阅读书单)，算是自2018年以来读书最多的一个年份了。其中不乏拖了近3年的那本《西方文化中的数学》。接着就来絮叨絮叨今年看的这12本书吧。 《莱博维茨的赞歌》 第一次被安利《莱博维茨的赞歌》的机核的电台节目辐射－视觉、音乐以及文学, 当时听完节目就相当好奇，可以被一部载入史册的CRPG游戏誉为精神文本的小说到底是个什么样子的。但是当时新星版的译本几乎就是绝本了，某鱼的二手价也要已经飙到了3位数。直到今年年初在核市节目上听到了中信版译本的消息,才有机会买来拜读。 全书通过3个故事讲述了核战灭世后莱博维茨修道院从保卫文明，到重建，然后看着文明再度毁灭的故事。各种无不透露着辐射那股 War, War never changed的味道。 《占星术杀人事件》《屋顶上的小丑》《亿男》 这3本书都是2019年上海书展上买的。前两本都是岛田庄司的推理名篇，其中《占星术杀人事件》在本格派推理史上有着非凡的地位，各种被抄袭从未被超越过。《屋顶上的小丑》要是最吸引人的话就是多线叙事，每条线都掐在恰如其分的地方。《亿男》则是挂着悬疑羊头卖着人生哲理。 《神经漫游者》 威廉吉布森的蔓生三部曲之一，开创了赛博朋克的科幻流派，说实话这本书我看的很痛苦，很多地方实在读不懂，到现在我还是不明白那些无法读懂的地方到底是原著如此，还是翻译的不行，亦或者是Kindle版排版太烂了。 《神们自己》，《神的九十亿个名字》 阿瑟克拉克的中篇小说和短篇小说集，这两本书阅读体验奇佳，尤其是在读完《神经漫游者》后，虽然三本书被Amazon打在同一个包里来卖的，但是光从排版上就比《神经漫游者》高出不少，所以才会有我对后者排版问题的质疑。 《神们自己》三线叙事，讲述了2个平行宇宙中的2个物种在能源，种族存续，家庭伦理上的各种讨论和故事。 《神的九十亿个名字》作为短篇小说集收录了好几篇风格题材迥异的小说，花上十几分钟读上一个故事是相当惬意的。 《佐伊的战争》 《人类决裂》 《万物的终结》 约翰斯卡尔齐的《老人的战争》系列的后3部，前三部大概是3，4年前读的吧，在这个宇宙观里最吸引人的设定就绿皮的人类防卫军战士，以及跨种族间的政治斗争。系列的六本书相当于在这个大设定下讲的六个故事。每个故事虽说都是独立的故事，但是前后皆有关联，而且最重要的就是每本的长度都算不上很长，相当适合于一口气读完。 《西方文化中的数学》 这本书大概是从2017年开始读的，当时意气奋发觉得对于理科生出身的我，书中内容应该很好理解，没想到最后不光是文化还是数学读的都是一知半解。只能说自大了。 《一想到还有95%的问题留给人类，我就放心了》 大概是18年还是19年前后对量子物理和宇宙物理开始有了兴趣，虽然各中理论并不是很了解，但是仍然很好奇的买了这本书，全书插画相当有趣，同时使用浅显易懂的语言来解释各种复杂的物理现象，以及当今人类物理知识的边界。强烈推荐给想假装成学霸的朋友。 2021年读什么 具体读啥还没想好基本上还是以科幻和悬疑为主，但是肯定会读的应该有海明威的《丧钟为谁而鸣》和小林泰三的《醉步男》吧。","link":"/2020/12/29/2020%E5%B9%B4%E9%98%85%E8%AF%BB%E6%80%BB%E7%BB%93/"},{"title":"Largrange项目架构与设计回顾 (二)","text":"在Largrange项目架构与设计回顾 (一) 里面我讲了一下项目开始架构和技术选型的一些内容。这一章来聊聊业务设计上的这点事。 总体来说项目设计的时候,我们对业务模块的划分和拆解总体上来说都是遵循着高内聚,低耦合的原则来进行划分的。大部分和业务相关的服务,都还是能很好的进行功能划分的。但是有一些和具体业务关联性并不是很高的服务在界定与实现时出现了一些问题。 任务调度服务由于平台方面会有一些控制命令下发给Android设备,而且下发的命令并不一定都是实时的,大部分都是指定一个时间来下发,所以在设计的时候就考虑到需要一个任务调度服务(以下略称cron),来处理这些下发指令以及未来可能会有的定时批处理任务的业务需求。技术选型的时候考虑到整个服务是构建在Kubernetes上的一个分布式的微服务架构,所以就没有选择Spring Scheduler,而是使用了Quarter来支撑整个cron。 从技术选型上来说cron没有什么问题,但是在设计如何使用cron上还是有点问题的, 我们先来看看已推送服务为例,整个平台中cron的处理流程是怎样的。 Platform 调用 cron的创建定时任务Job的接口(接口的参数为推送时使用的相关参数) cron 创建Quartz的Job和Trigger,并将Job和Trigger的Name(Quartz中Job和Trigger的唯一标识符)返回个Platform cron 在指定时间触发推送的Job,即调用Push服务的推送接口 Push的推送接口调用第三方服务商的推送服务,并将第三方推送服务的调用结果返回给cron cron通过调用Platform预留的推送服务回调地址将第三方推送服务调用接口返还给Platform Platform 将第三方推送服务的调用结果留档保存,并继续业务处理 设计之初考虑到不想在cron中牵扯到具体的业务, 所以设计了一个Platform的回调接口来处理推送后的具体业务处理。虽然保证了cron尽量减少了和业务逻辑接触与数据库的访问。但是前前后后要访问集群内部的其他微服务2次,额外增加了网络开销,以及因为网络通信造成额外的通信失败风险。而且针对每种不同的定时任务,都需要额外开发一个QuartzJobBean,很难形成统一的QuartzJobBean来进行处理。今后如果还有相似项目还是需要重新考量一下如何设计一个更加完善的定时任务。 总结暂时就想到了这些东西,今后想到啥还会继续在这里补存。","link":"/2020/05/21/Lagrange%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE2/"},{"title":"Spring Cloud Kubernetes环境下使用Jasypt","text":"前言最近半年着手开始做了基于微服务的中台项目，整个项目的技术栈采用的是Java + Spring Cloud + Kubernetes + Istio。 业务开放上还是相当顺利的。但是在安全审核上，运维组提出了一个简易。现在项目一些敏感配置，例如MySQL用户的密码，Redis的密码等现在都是明文保存在Kubernetes的ConfigMap中的(是的，我们并没有Nacos作为微服务的配置中心)。这样可能存在安全隐患。 首次尝试既然有问题，那就解决问题。要给配置文件中的属性项目加密很简单，稍微Google一下，就有现成的方案了。 现在比较常用的解决方案就是集成Jasypt,然后通过jasypt-spring-boot-starter来融合进Spring。 POM包加入jasypt-spring-boot-starter12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.4&lt;/version&gt;&lt;/dependency&gt; Dockerfile中增加java参数12...ENTRYPOINT [&quot;sh&quot;,&quot;-c&quot;,&quot;java $JAVA_OPTS -jar app.jar --jasypt.encryptor.password=helloworld $PARAMS&quot;] 在ConfigMap中添加加密属性1234567apiVersion: v1kind: ConfigMapmetadata: name: demodata: application.yaml: |- test2: ENC(94Y7Ds3+RKraxQQlura9sDx+9yF0zDLMGMwi2TjyCFZOkkHfreRFSb6fxbyvCKs7) 利用actuator接口测试在management.endpoints.web.exposure.include属性中增加env，这样我们就可以通过调用/actuator/env来查看一下env接口返回的整个Spring 容器中所有的PropertySource。 1234567891011121314{ ... &quot;propertySources&quot;: [ { &quot;name&quot;: &quot;bootstrapProperties-configmap.demo.default&quot;, &quot;properties&quot;: { &quot;test2&quot;: { &quot;value&quot;: &quot;Hello,world&quot; } } } ... ]} OK, 这下配置项已经加密了。问题解决了。 但是… 新的问题自从项目集成了Jayspt以后，出现了一个奇怪的问题。每次项目试图通过修改ConfigMap的配置文件，然后试图通过spring-cloud-starter-kubernetes-fabric8-config来做自动Reload，都失败了。然而查阅应用日志，并没有出现任何异常。无奈只能打开spring-cloud和jasypt-spring-boot的DEBUG日志。 进过几天对日志和两边源代码的分析。终于找到了原因 原因在Spring Boot启动时jasypt-spring-boot会将下面6种配置(并不仅限与这6种配置文件) Classpath下的application.yaml Classpath下的bootstrap.yaml 集群里名称为${spring.cloud.kubernetes.config.name}的ConfigMap 集群里名称为${spring.cloud.kubernetes.config.name}-kubernetes的ConfigMap Java启动参数 环境变量 转换成jasypt-spring-boot自己的PropertySource实现类EncryptableMapPropertySourceWrapper。 但是如果使用Kubernetes的ConfigMap来作微服务配置中心的时候，Spring Cloud会在ConfigurationChangeDetector中查找配置类org.springframework.cloud.bootstrap.config.BootstrapPropertySource, 并依据BootstrapPropertySource的类型来判断容器内的配置与集群中ConfigMap里的配置是否有差异,来触发配置reload。 由于jasypt-spring-boot已经将所有的配置文件转型成了EncryptableMapPropertySourceWrapper, 所以ConfigurationChangeDetector无法找到BootstrapPropertySource所以会一直任务ConfigMap的里的配置没有变化，导致整个Reload失效(无论是使用polling还是event方式) 解决问题为了保证ConfigMap变化后自动Reload的功能，所以jasypt-spring-boot不能把BootstrapPropertySource转换成EncryptableMapPropertySourceWrapper 所以我们需要设置jasypt.encryptor.skip-property-sources配置项, Classpath中的application.yaml需要增加配置 123jasypt: encryptor: skip-property-sources: org.springframework.cloud.bootstrap.config.BootstrapPropertySource skip-property-sources配置项配置后，加密项目就不能配置在ConfigMap里了，毕竟已经被我们忽略了。那么我们只能另外找一个PropertySource来存放加密项目了。 Classpath中的两个Yaml由于编译时会被Maven打包进Jar文件，会牵涉多个CI/CD多个流程显然不合适，启动参数配置项的也要影响到Docker镜像制作这个流程。所以判断下来最适合的PropertySource就是环境变量了。 环境变量增加加密项在Kubernetes的部署Yaml中，添加加密数据项application.test.str 123456789101112131415161718192021222324apiVersion: apps/v1kind: Deploymentmetadata: labels: app: demo name: demospec: replicas: 1 selector: matchLabels: app: demo template: metadata: labels: app: demo spec: containers: - env: - name: TZ value: Asia/Shanghai - name: application.test.str value: &gt;- ENC(94Y7Ds3+RKraxQQlura9sDx+9yF0zDLMGMwi2TjyCFZOkkHfreRFSb6fxbyvCKs7) .... 如果需要更加严密的加密方针的话，我们可以把环境变量的内容放进Kubernetes的Secrets中。 在ConfigMap中引用application.test.str12345678apiVersion: v1kind: ConfigMapmetadata: name: demodata: application.yaml: |- test2: ENC(94Y7Ds3+RKraxQQlura9sDx+9yF0zDLMGMwi2TjyCFZOkkHfreRFSb6fxbyvCKs7) test3: ${application.test.str} 通过actuator接口来测试通过actuator\\env接口来测试一下 1234567891011121314151617{ ... &quot;propertySources&quot;: [ { &quot;name&quot;: &quot;bootstrapProperties-configmap.demo.default&quot;, &quot;properties&quot;: { &quot;test2&quot;: { &quot;value&quot;: &quot;ENC(94Y7Ds3+RKraxQQlura9sDx+9yF0zDLMGMwi2TjyCFZOkkHfreRFSb6fxbyvCKs7)&quot; }, &quot;test3&quot;: { &quot;value&quot;: &quot;Hello,world&quot; } } } ... ]} 这样ConfigMap中的配置项test3就可以通过环境变量引用并使用加密配置项了。同时修改ConfigMap依然可以触发auto reload了。这下终于算是解决了。","link":"/2021/09/29/Spring-Cloud-Kubernetes%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BD%BF%E7%94%A8Jasypt/"},{"title":"在ubuntu上从零搭建node.js + nginx + mongodb环境","text":"说到后端开发环境，最有名的莫过于LAMP和LNMP，最近由于node.js的强势崛起，越来越多的后端开发也开始试水node.js了。我最近也因为各种原因，前前后后总够构建了好几台node.js + nginx + mongodb的Linux服务器。 首先关于Linux服务器，比起CentOS来说，我更加喜欢ubuntu一点。所以无论是阿里云还是一些海外的vps服务器上，我也倾向选用ubuntu服务器，本贴也是基于ubuntu服务器里说明的。 1.开始前的一些准备首先还是需要刷新一下ubuntu的包索引并安装build-essential和libssl-dev这2个包以及curl这个工具。 123sudo apt-get updatesudo apt-get install build-essential libssl-devsudo apt-get isntall curl 2.安装node.js关于安装node.js这一点，我不是很推荐使用apt-get 来安装node.js的环境。主要是因为node.js和io.js合并以后，版本迭代速度相当频繁(主要还是因为更多ES6的特性得到了支持）。今后很有可能会有在一台服务器上使用不同版本的node.js的需求。 这里推荐一个管理不同版本node.js的工具：nvm，官网: https://github.com/creationix/nvm 。安装nvm，如果前面你安装了curl的话可以 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash 如果没有按照curl的话，也可以使用wget来进行安装 1wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash 然后nvm就会自动安装到home目录下面的.nvm目录里，并会在.bashrc里自动添加nvm的环境变量。为了让环境变量生效，最简单的方法就是通过ssh或是telnet重新连接你的服务器。 安装完nvm后，就可以通过nvm来安装指定版本的node.js了。 12345# 列出可以安装的node版本号nvm ls-remote# 安装指定版本的node (当前最新版本为v5.7.1, LTS版是v4.3.2)nvm install v4.3.2 3.安装nginx由于ubuntu源（尤其是阿里云的源）上的nginx经常不是最新的，如果需要安装最新版本nginx的时候需要手动添加nginx的源。 1234567891011# 添加nginx的mainline仓库cd /tmp/ &amp;&amp; wget http://nginx.org/keys/nginx_signing.keysudo apt-key add nginx_signing.key# 编辑/etc/apt/sources.list.d/nginx.list 添加下面2行内容，井号不需要# deb http://nginx.org/packages/mainline/ubuntu/ ubuntu代号 nginx# deb-src http://nginx.org/packages/mainline/ubuntu/ ubuntu代号 nginxsudo vi /etc/apt/sources.list.d/nginx.list# 更新源，并安装nginxsudo apt-get update &amp;&amp; sudo apt-get install nginx 在编辑/etc/apt/sources.list.d/nginx.list的时候需要注意，“ubuntu代号”需要根据ubuntu服务器的版本不同手动调整的，比如14.04是trusty。通过下面的命令可以获取ubuntu的代号。 1lsb_release -cs 4.安装mongodb同样和nginx有同样的问题，要安装最新3.2版本的mongodb也需要手动添加ubuntu的源。 1234567891011# 导入mongodb的public keysudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv EA312927# 生成mongodb的源listecho &quot;deb http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.list# 更新源sudo apt-get update# 安装最新版本的mongodbsudo apt-get install -y mongodb-org 以上一台node.js + nginx + mongodb的ubuntu服务器就完成了。","link":"/2019/12/09/hot-to-install-nodejs-nginx-mongodb-on-ubuntu/"},{"title":"Largrange项目架构与设计回顾 (一)","text":"项目背景 从去年年底开始一个老客户希望在他们的一个传统的机械设备(后面略称 E机关 )上外装一个Android设备。 Android设备和 E机关 之间通过串口或是RJ45接口进行数据交互，主要是Android设备获取 E机关 内部的数据，并不会通过接口来控制 E机关 。 Android设备则通过4G 来和平台交互，上报Android设备的状态数据，同时接受平台的控制。以此来实现让传统机械设备也能拥抱物联网的概念。 最后围绕着客户的需求分成了3个项目来并行推进 Android设备的硬件设备的设计、选材、样机制作与量产规划 在Android设备上,进行与E机关以及平台进行交互的APP开发 用于Android设备交互的平台的架构、设计与开发 我们平台Team就负责 3.用于Android设备交互的平台 并命名Lagrange (拉格朗日) 。 设计&amp;架构整个平台这块不仅需要向Android设备的APP提供数据交互接口，还需要有一个供相关运营人员使用的前端Web应用，以及与云平台(主要是Aliyun) 交互的功能。所以考虑到多方面使用微服务的架构来实现整个平台端。由于E机关的工作工况不能保证长期较的稳定的连接到4G网络，所以我们并不考虑使用Socket长连接的方式来做APP和平台之间的数据交互，要实现平台对Android设备进行反控的话，只能实现推送方式来把控制命令下发给Android设备,所以还需要有一个第三方推送服务商交互的服务。同时控制推送也有实时和非实时以及定期推送的需求，所以可能还需要一个任务调度的服务。 根据对上述业务进行梳理，我们将项目分成几个服务 提供Android设备的交互接口的 App Service 提供运营人员使用前端Web应用 Platform Web Service 前端Web应用使用到的一些接口 Platform Service 负责第三方推送服务商交互的 Push Service 提供云平台鉴权用的 Auth Service 用来管理任务调度的 Cron Service 由于前一个项目实施的时候没有使用容器部署，每当访问量峰值的时候，我们这些码农兼运维就各种加班，所以这次项目决定直接将服务容器化，同时选择了Kubernetes来管理容器。由于客观原因线上的Kubernetes直接购买了Aliyun的托管版Kubernetes服务。 内部的开发测试环境则使用了 Rancher 2.0 来构建Kubernetes集群。 技术选型a. 后端服务选型由于不考虑长连接的原因，所以在后端服务在技术选型上基本就不考虑Netty了，直接上Spring大礼包。 Spring Boot 开发接口 Spring Data 配合 JPA 来进行数据的持久化 Spring Cloud Kubenetes 来做数据的Config的autoreload Quartz 负责处理任务调度 服务之间调用都使用HTTP服务, 服务发现也有Kubernetes的DNS机制支持。服务网格则选择了比较成熟的Istio，主要还是Aliyun的Kubernetes可以集成Istio，部署和使用都相当方便。 b. 前端Web应用选型因为前端Web应用主要是给运营人员使用，所以我们考虑使用Single Page Application来做个前后端分离的Web应用。框架这块由于团队成员基本上没有什么前端开发经验，基本都是后台写Java的码农，所以框架选择有点随性，直接就点名了vue.js。前端控件库则用的是阿里系的Antd。 c. 数据持久层主数据库选择了mysql，缓存用的redis。这些都是团队比较熟悉的。由于一些特殊的业务需求和使用场景，我们还加了一个mongodb来做为一个副数据库，主要存放一些特殊业务使用的数据。 d. DevOps用了相当传统的GitLab CE 加上Jenkins的组合，实现前后端代码的自动编译，推送到私有的镜像仓库(使用Aliyun的镜像仓库服务) 最后以上基本是项目最早做设计时候的各种考量。暂时先写这么多，过两天再回顾一下当初设计上有哪些觉得不足的地方。","link":"/2020/05/09/lagrange%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"title":"重学Java (一) 泛型","text":"1. 前言泛型编程自从 Java 5.0 中引入后已经超过15个年头了。对于现在的 Java 码农来说熟练使用泛型编程已经是家常便饭的事情了。所以本文就在不对泛型的基础使用在做说明了。 如果你还不会使用泛型的话，可以参考下面两个链接 Java 泛型详解 The Java™ Tutorials (Lesson: Generics) 这篇文章就简答聊一下，我实际在开发工作中很少用的到泛型方法这个知识点，以及在实际项目中有哪些东西会使用到泛型。 2. 泛型方法在阅读代码的时候我们经常会看到下面这样的方法 (这段代码摘自 java.util.AbstractCollection) 123456789101112131415161718192021222324252627 public &lt;T&gt; T[] toArray(T[] a) { // Estimate size of array; be prepared to see more or fewer elements int size = size(); T[] r = a.length &gt;= size ? a : (T[])java.lang.reflect.Array .newInstance(a.getClass().getComponentType(), size); Iterator&lt;E&gt; it = iterator(); for (int i = 0; i &lt; r.length; i++) { if (! it.hasNext()) { // fewer elements than expected if (a == r) { r[i] = null; // null-terminate } else if (a.length &lt; i) { return Arrays.copyOf(r, i); } else { System.arraycopy(r, 0, a, 0, i); if (a.length &gt; i) { a[i] = null; } } return a; } r[i] = (T)it.next(); } // more elements than expected return it.hasNext() ? finishToArray(r, it) : r;} 那么 pulic 关键字后面的那个 &lt;T&gt; 就是用来标记这个方法是一个泛型方法。 那什么是泛型方法呢。 官方的解释是这样的 1Generic methods are methods that introduce their own type parameters. This is similar to declaring a generic type, but the type parameter's scope is limited to the method where it is declared. Static and non-static generic methods are allowed, as well as generic class constructors. 通俗点来将就是将一个方法泛型化，让一个普通的类的某一个方法具有泛型功能。 如果在一个泛型类中增加一个泛型方法，那这个泛型方法就可以有一套独立于这个类的泛型类型。 通过一个简单的例子, 我们来看看 123456789101112131415161718192021/** * GenericClass 这个泛型类是一个简单的套皮的 HashMap */public class GenericClass&lt;K, V&gt; { private Map&lt;K, V&gt; map = new HashMap&lt;&gt;(); public V put(K key, V value) { return map.put(key, value); } public V get(K key) { return map.get(key); } // 泛型方法 genericMethod 可以接受一个全新的、作用域只限本函数的泛型类型T public &lt;T&gt; T genericMethod(T t) { return t; }} 实际使用起来 123456GenericClass&lt;String, Integer&gt; map = new GenericClass&lt;&gt;();// put 和 get 方法的参数必须使用定义时指定的 String 和 IntegerSystem.out.println(map.put(&quot;One&quot;, 1));System.out.println(map.get(&quot;One&quot;));// 泛型方法 genericMethod 就可以接受一个 String 和 Integer 以外的类型System.out.println(map.genericMethod(new Double(1.0)).getClass()); 我们再来看看 JDK 中使用到泛型方法的例子。我们最常使用的泛型容器 ArrayList 中有个 toArray 方法。JDK 在它的实现中就提供了两个版本，其中一个就是泛型方法的版本 12345678910111213141516171819public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { // 这是一个普通版本，返回一个Object的数组 public Object[] toArray() { return Arrays.copyOf(elementData, size); } // 这是一个泛型方法的版本，将容器里存储的元素输出到 T[] 数组中。 其中 T 必须是 E 的父类，否则 System.arraycopy 会抛出 ArrayStoreException 异常 public &lt;T&gt; T[] toArray(T[] a) { if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; }} 泛型方法总体上来说就是可以给与现有的方法实现上，增加一个更加灵活的实现可能。 3. 实战应用在实际的项目中，对于泛型的使用，除了像倾倒垃圾一样往泛型容易里塞各种 java bean 和其他泛型对象。还能怎么使用泛型呢？ 我们在实际的一些项目中，会对数据库中的一些表(多数时候是全部)先实现 CRUD (Create, Read, Update, Delete)的操作，并从这些操作中延伸出一些简单的 REST 风格的 WebAPI 接口，然后才会根据实际业务需要实现一些更复杂的业务接口。 大体上会是下面这个样子。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// 这是一个简单的 Entity 对象// 通常现在的 Java 应用都会使用到 Lombok 和 Spring Boot@Data@AllArgsConstructor@NoArgsConstructor@ToString@Entity@Table(name = &quot;user&quot;)public class User { @Id private Long id; private String username; private String password;}// 然后这个是 DAO 接口继承自 spring-data 的 JpaRepositorypublic interface UserDao extends JpaRepository&lt;User, Long&gt; {}// 在来是一个访问 User 资源的 Service 和他的实现public interface UserService { List&lt;User&gt; findAll(); Optional&lt;User&gt; findById(Long id); User save (User user) void deleteById(Long id);}@Servicepublic class UserSerivceImpl implements UserService { private UserDao userDao; public UserServiceImpl(UserDao userDao) { this.userDao = userDao; } @Override public List&lt;User&gt; findAll() { return this.dao.findAll(); } @Override public Optional&lt;User&gt; findById(Long id) { return this.dao.findById(id); } @Override public User save(User user) { return this.dao.save(user); } @Override public void deleteById(Long id) { this.dao.deleteById(id); }}// 最后就是 WebAPI 的接口了@RestController@RequestMapping(&quot;/user/&quot;)public class UserController{ private UserService userService; public UserController(userService userService) { this.userService = userService; } @GetMapping @ResponseBody public List&lt;User&gt; fetch() { return this.userService.findAll(); } @GetMapping(&quot;{id}&quot;) @ResponseBody public User get(@PathVariable(&quot;id&quot;) Long id) { // 由于是示例这里就不考虑没有数据的情况了 return this.userService.findById(id).get(); } @PostMapping @ResponseBody public User create(@RequestBody User user) { return this.userService.save(user); } @PutMapping(&quot;{id}&quot;) @ResponseBody public User update(@RequestBody User user) { return this.userService.save(user); } @DeleteMapping(&quot;{id}&quot;) @ResponseBody public User delete(@PathVariable(&quot;id&quot;) Long id) { User user = this.userService.findById(id); this.userService.deleteById(id); return user; }} 大致一个表的一套相关接口就是这个样子的。如果你的数据库中有大量表的话，而且每个表都需要提供 REST 风格的 WebAPI 接口的话，那么这将是一个相当枯燥的而又及其容易出错的工作。 为了不让这项枯燥而又容易犯错的工作占去我们宝贵的私人时间，我们可以通过泛型和继承的技巧来重构从 Service 层到 Controller 的这段代码(感谢 spring-data 提供了 JpaRepository, 让我们不至于从 DAO 层重构) 3.1 Service 层的重构首先是 Service 接口的重构，我们 Service 层接口就是定义了一组 CRUD 的操作，我们可以将这组 CRUD 操作抽象到一个父接口，然后所有 Service 层的接口都将继承自这个父接口。而接口中出现的 Entity 和主键的类型(上例中 User 的主键 id 的类型是 Long)就可以用泛型来展现。 1234567891011// 这里泛型表示 E 来指代 Entity, ID 用来指代 Entity 主键的类型public interface ICrudService&lt;E, ID&gt; { List&lt;E&gt; findAll(); Optional&lt;E&gt; findById(ID id); E save(E e); void deleteById(ID id);}// 然后 Service 层的接口，就可以简化成这样public interface UserService extends ICrudService&lt;User, Long&gt; {} 同样 Service 层的实现也可以使用相似的方法具体实现可以抽象到一个基类中。 1234567891011121314151617181920212223242526272829303132// 相比 ICrudService 这里有多了一个泛型 T 来代表 Entity 对应的 DAO, 我们的每一个 DAO 都继承自// spring-data 的 JpaRepository 所以，这里可以使用到泛型的边界public abstract class AbstractCrudService&lt;T extends JpaRepository&lt;E, ID&gt;, E, ID&gt; { private T dao; public AbstractCrudService(T dao) { this.dao = dao; } public List&lt;E&gt; findAll() { return this.dao.findAll(); } public Optional&lt;E&gt; findById(ID id) { return this.dao.findById(id); } public E save(E e) { return this.dao.save(e); } public void deleteById(ID id) { this.dao.deleteById(id); }}// 那 Service 的实现类可以简化成这样@Servicepublic class UserServiceImpl extends AbstractCrudService&lt;UserDao, User, Long&gt; implements UserService { public UserServiceImpl(UserDao dao) { supper(dao); }} 同样我们可以通过相同的方法来对 Controller 层进行重构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Controller 层的基类public abstract class AbstractCrudController&lt;T extends ICrudService&lt;E, ID&gt;, E, ID&gt; { private T service; public AbstractCrudController(T service) { this.service = service; } @GetMapping @ResponseBody public List&lt;E&gt; fetch() { return this.service.findAll(); } @GetMapping(&quot;{id}&quot;) @ResponseBody public E get(@PathVariable(&quot;id&quot;) ID id) { // 由于是示例这里就不考虑没有数据的情况了 return this.service.findById(id).get(); } @PostMapping @ResponseBody public E create(@RequestBody E e) { return this.service.save(e); } @PutMapping(&quot;{id}&quot;) @ResponseBody public E update(@RequestBody E e) { return this.service.save(e); } @DeleteMapping(&quot;{id}&quot;) @ResponseBody public E delete(@PathVariable(&quot;id&quot;) ID id) { E e = this.service.findById(id).get(); this.service.deleteById(id); return e; }}// 具体的 WebAPI@RestController@RequestMapping(&quot;/user/&quot;)public class UserController extends AbstractCrudController&lt;UserService, User, Long&gt; { public UserController(UserService service) { super(service); }} 经过重构可以消减掉 Servcie 和 Controller 中的大量重复代码，使代码更容易维护了。 4. 结尾关于泛型就简单的说这些了，泛型作为 Java 日常开发中一个常用的知识点，其实还有很多知识点可以供我们挖掘，奈何本人才疏学浅，这么多年工作下来，只积累出来这么点内容。 文末放上示例代码的代码库: GitHub入口 gitee入口","link":"/2021/03/15/%E9%87%8D%E5%AD%A6Java-%E4%B8%80-%E6%B3%9B%E5%9E%8B/"},{"title":"阿里云Kubernetes上线踩坑记","text":"12Update:2020-04-08 增加istio-ingressgateway高可用的设置 最近公司因为项目需要，在阿里云上部署了一个Kubernetes集群。虽然阿里云的文档说的还算细致，但是还是有些没有明确说明的细节。 1. 购买篇申请项目预算的时候，只考虑到Worker节点，1个SLB节点以及域名和证书的预算。但是实际购买的时候发现还有许多额外的开销。 1.1 SNAT这个和EIP一并购买，可以方便通过公网使用kubectl访问集群。关于SNAT网关至今不是很明白需要购买这个服务的意义何在，只是为了一个EIP来访问集群吗？ 1.2 Ingress这个选上了后，阿里云会给你买个SLB而且还是带公网访问的，如果你后期考虑使用Istio的话，建议你集群创建后，直接停止这个SLB，以免产生额外的费用。 1.3 日志服务通过阿里云的日志服务来收集应用的的日志，挺好用的。但是另外收费，如果有能力的自建日志服务的可不购买。 2. Istio阿里云的Kubernetes集群完美集成了Istio，根据向导就能很简单的部署成功。 2.1 额外的SLBIstio的Gateway 需要绑定一个新的SLB，和Ingress的SLB不能是同一个，又是一笔额外的开销 2.2 集群外访问这个在阿里云的Istio FAQ中有提到，按照指导很容易解决 2.2 SLB的443监听为了方便443端口的证书绑定，我们直接删除了SLB上原有的443监听(TCP协议), 重新建了一个443监听(HTTPS协议)，指向和80端口同样的虚拟服务器组。但是设置健康检查时一直出错，经过排查发现SLB健康检查发送的请求协议是HTTP 1.0的，Istio的envoy直接反悔了426(Upgrade Required)这个状态码，所以我们无奈只能把健康检查的检查返回状态改为http_4xx，这样就能通过SLB的健康检查了。 2.3 istio-ingressgateway的高可用istio-ingressgateway要达成高可用，只需要增加通过伸缩POD就可以实现，于istio-ingressgateway对应的SLB中的虚拟服务器组也会自动增加，完全不需要进行额外的手动设定。 由于istio-ingressgateway中挂载了HPAHorizontalPodAutoscaler(简称HPA)，通常三节点的集群中最小POD数只有1台，在3节点的集群中，要实现高可用，需要手动修改HPA，增加最小POD数。 基本上现在遇到了这些坑，再有在总结吧。","link":"/2020/04/01/%E9%98%BF%E9%87%8C%E4%BA%91Kubernetes%E4%B8%8A%E7%BA%BF%E8%B8%A9%E5%9D%91%E8%AE%B0/"}],"tags":[{"name":"阅读","slug":"阅读","link":"/tags/%E9%98%85%E8%AF%BB/"},{"name":"架构","slug":"架构","link":"/tags/%E6%9E%B6%E6%9E%84/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"Aliyun","slug":"Aliyun","link":"/tags/Aliyun/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"node.js","slug":"node-js","link":"/tags/node-js/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"generic","slug":"generic","link":"/tags/generic/"}],"categories":[{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"},{"name":"设计","slug":"设计","link":"/categories/%E8%AE%BE%E8%AE%A1/"},{"name":"后端","slug":"后端","link":"/categories/%E5%90%8E%E7%AB%AF/"},{"name":"Cloud","slug":"后端/Cloud","link":"/categories/%E5%90%8E%E7%AB%AF/Cloud/"}]}